# Qubits {#qubits}

> About **quantum bits** and **quantum circuits**, including the "impossible" **square root of $\texttt{NOT}$**, as well as an introduction to **single-qubit unitaries** and rotations of the **Bloch sphere**, and the implications concerning **universal gates**.

When studying classical information theory, one single bit isn't usually the most interesting object to think about --- it's either $0$ or $1$.
Yet in the quantum case, just working with one "quantum bit" (which we call a **qubit**) opens up a whole world of interesting mathematics.
In fact, **single-qubit interference** is arguably *the* fundamental building block for quantum computing, and so deserves to be thoroughly investigated and understood.





## Composing quantum operations

In order to understand something in its full complexity it is always good to start with the simplest case.
Let us take a closer look at quantum interference in the simplest possible computing machine: the one that has only two distinguishable configurations  --- two quantum states --- which we label as $\ket{0}$ and $\ket{1}$.
We prepare the machine in some input state, usually $\ket{0}$, and let it **evolve**: the machine undergoes a prescribed sequence of computational steps, each of which induces transitions between the two "computational states" $\ket{0}$ and $\ket{1}$.
The machine then ends in the output state $\ket{\psi}=\alpha_0\ket{0}+\alpha_1\ket{1}$, meaning the two outputs, $\ket{0}$ and $\ket{1}$, are reached with probability amplitudes $\alpha_0$ and $\alpha_1$, respectively.
In the process of computation each computational step $U$ (also referred to as an **operation**) sends state $\ket{k}$ to state $\ket{l}$, where $k,l=0,1$, but only with some **amplitude** $U_{lk}$.
We write this as
$$
  \ket{k} \longmapsto \sum_l U_{lk} \ket{l}.
$$
(watch out for the order of the indices).

Thus any computational step $U$ of this machine can be described by a matrix which tabulates all the transition amplitudes:
$$
  U =
  \begin{bmatrix}
    U_{00} & U_{01}
  \\U_{10} & U_{11}
  \end{bmatrix}.
$$
The matrix element $U_{lk}$ represents the amplitude of transition from state $\ket{k}$ to state $\ket{l}$ (again, watch the order of indices).
To be clear, the entries in this matrix are not any random complex numbers: their moduli squared represent transition probabilities, which in turn implies that such matrices must be **unitary**.^[Recall that matrix $U$ is called **unitary** if $$U^\dagger U = UU^\dagger = \id$$ where the **adjoint** or **Hermitian conjugate** $U^\dagger$ of any matrix $U$ with complex entries $U_{ij}$ is obtained by taking the complex conjugate of every element in the matrix and then interchanging rows and columns ($U^\dagger_{kl}= U^\star_{lk}$).]

We can also describe $U$ by drawing a diagram, which contains exactly the same information as the matrix representation, but just in a different form:

```{r,engine='tikz',fig.width=3.5}
\tikzset{dot/.style={fill,shape=circle,minimum size=5pt,inner sep=0pt}}
\newcommand{\ket}[1]{|#1\rangle}
\begin{tikzpicture}[xscale=0.8,yscale=1.6]
\node (input0) at (0,1) {$\ket{0}$};
\node (input1) at (0,0) {$\ket{1}$};
\node (output0) at (5,1) {$\ket{0}$};
\node (output1) at (5,0) {$\ket{1}$};
\foreach \x in {1,4}
  \foreach \y in {0,1}
    \node [dot] (n\x\y) at (\x,\y) {};
\draw [thick] (input0) to node [fill=white,pos=0.5] {$U_{00}$} (output0);
\draw [thick] (input1) to node [fill=white,pos=0.5] {$U_{11}$} (output1);
\draw [thick] (n11) to node [fill=white,pos=0.25] {$U_{10}$} (n40);
\draw [thick] (n10) to node [fill=white,pos=0.25] {$U_{01}$} (n41);
\end{tikzpicture}
```

Now how can we find some quantum interference to study?
Consider two computational steps, $U$ and $V$.
What is the amplitude that input $\ket{k}$ will generate output $\ket{m}$?
We have to check all computational paths leading from input $\ket{k}$ to output $\ket{m}$ and add the corresponding amplitudes.
For example, as you can see in Figure \@ref(fig:composition-of-two-computation-steps), input $\ket{0}$ and output $\ket{1}$ are connected by the two computational paths: $\ket{0}\mapsto\ket{0}\mapsto\ket{1}$ (amplitude $V_{10}U_{00}$) and $\ket{0}\mapsto\ket{1}\mapsto\ket{1}$ (amplitude $V_{11}U_{10}$).
Thus the total amplitude that input $\ket{0}$ gives output $\ket{1}$ is the sum $V_{10}U_{00}+V_{11}U_{10}$, and when we take the modulus squared of this expression we will see the interference term.

(ref:composition-of-two-computation-steps-caption) The composition of two computational steps, $U$ and $V$, with the possible paths from $\ket{0}$ to $\ket{1}$ highlighted.

```{r composition-of-two-computation-steps,engine='tikz',fig.cap='(ref:composition-of-two-computation-steps-caption)'}
\definecolor{primary}{RGB}{177,98,78}
\tikzset{dot/.style={fill,shape=circle,minimum size=5pt,inner sep=0pt}}
\newcommand{\ket}[1]{|#1\rangle}
\begin{tikzpicture}[yscale=1.8]
  \node (input0) at (0,1) {$\ket{0}$};
  \node (input1) at (0,0) {$\ket{1}$};
  \node (middle0) at (5,1) {$\ket{0}$};
  \node (middle1) at (5,0) {$\ket{1}$};
  \node (output0) at (10,1) {$\ket{0}$};
  \node (output1) at (10,0) {$\ket{1}$};
  \foreach \x in {1,4,6,9}
    \foreach \y in {0,1}
      \node [dot] (n\x\y) at (\x,\y) {};
  \draw [thick] (input1) to (n10) to node [fill=white,pos=0.5] {$U_{11}$} (n40);
  \draw [thick] (n60) to node [fill=white,pos=0.25] {$V_{01}$} (n91);
  \draw [thick] (n10) to node [fill=white,pos=0.25] {$U_{01}$} (n41);
  \draw [thick] (n61) to node [fill=white,pos=0.5] {$V_{00}$} (n91) to (output0);
  \draw [ultra thick,primary] (input0) to node [fill=white,pos=0.5] {$U_{00}$} (middle0);
  \draw [ultra thick,primary] (n40) to (middle1);
  \draw [ultra thick,primary] (n11) to node [fill=white,pos=0.25] {$U_{10}$} (n40);
  \draw [ultra thick,primary] (middle0) to (n61);
  \draw [ultra thick,primary] (middle1) to node [fill=white,pos=0.5] {$V_{11}$} (output1);
  \draw [ultra thick,primary] (n61) to node [fill=white,pos=0.25] {$V_{10}$} (n90);
  \node [dot] at (n11) {};
  \node [dot] at (n41) {};
  \node [dot] at (n60) {};
  \node [dot] at (n90) {};
\end{tikzpicture}
```

In general, given $U$ and $V$
$$
  \begin{aligned}
    \ket{k}
    &\longmapsto
    \sum_l U_{lk}\ket{l}
  \\\ket{l}
    &\longmapsto
    \sum_m V_{ml}\ket{m}
  \end{aligned}
$$
we can compose the two operations: we first apply $U$, and then $V$, to obtain
$$
  \begin{aligned}
    \ket{k}
    &\longmapsto
    \sum_l U_{lk} \left(
      \sum_m V_{ml}\ket{m}
    \right)
  \\&=
    \sum_m \left(
      \sum_l V_{ml}U_{lk}
    \right) \ket{m}
  \\&=
    \sum_m (VU)_{mk} \ket{m}.
  \end{aligned}
$$

If you want to hone your quantum intuition think about it the following way.
The amplitude that input $\ket{k}$ evolves to $\ket{m}$ via a specific intermediate state $\ket{l}$ is given by $V_{ml}U_{lk}$ (evolutions are independent so the amplitudes are multiplied).
This done, we have to sum over all possible values of $l$ (the transition can occur in several mutually exclusive ways so the amplitudes are added) to obtain $\sum_l V_{ml}U_{lk}$.
Thus the matrix multiplication $VU$ (watch the order of matrices) in one swoop takes care of the multiplication *and* addition of amplitudes corresponding to different computational paths.





## Quantum bits, called "qubits"

Such a two-state machine that we have just described in abstract terms is usually realised as a controlled evolution of a two-state system, called a **quantum bit**, or **qubit** for short.^[More general $n$-state systems can also be of interest, and are sometimes called **q-nits**; three-state systems in particular are sometimes called **qutrits**. In this book, however, we will only concern ourselves with qubits, since they readily generalise the classical notion of bits (and also give us more than enough interesting constructions to get started with!).]
For example, the state $\ket{0}$ may be chosen to be the lowest energy state of an atom (the **ground state**), and state $\ket{1}$ a higher energy state (the **excited state**).
Pulses of light of the appropriate frequency, duration, and intensity can take the atom back and forth between the basis states $\ket{0}$ and $\ket{1}$ (implementing logical $\texttt{NOT}$).

Some other pulses (say, half the duration or intensity) will take the atom into states that have no classical analogue.
Such states are called **coherent superpositions** of $\ket{0}$ and $\ket{1}$, and represent a qubit in state $\ket{0}$ with some amplitude $\alpha_0$ and in state $\ket{1}$ with some other amplitude $\alpha_1$.
This is conveniently represented by a state vector
$$
    \ket{\psi} =
    \alpha_0\ket{0} + \alpha_1\ket{1}
    \leftrightarrow
    \begin{bmatrix}
      \alpha_0
    \\\alpha_1
    \end{bmatrix}
$$

```{r,engine='tikz',fig.width=2}
\definecolor{primary}{RGB}{177,98,78}
\tikzset{blob/.style args={#1}{circle,draw,fill={#1}}}
\newcommand{\ket}[1]{|#1\rangle}
\begin{tikzpicture}[scale=0.7]
  \foreach \x in {0,2,4}
    \draw[thick] (0+\x,0) ellipse (20pt and 28pt);
  \foreach \x in {0,2,4}
    \draw (-0.4+\x,-0.4) to (0.4+\x,-0.4);
  \foreach \x in {0,2,4}
    \draw (-0.4+\x,0.4) to (0.4+\x,0.4);
  \node [blob=primary] at (0,0.4) {};
  \node [blob=primary] at (2,-0.4) {};
  \draw [fill=primary] (4,0) ellipse (3pt and 16pt);
  \node at (0,-1.4) {$\ket{0}$};
  \node at (2,-1.4) {$\ket{1}$};
  \node at (4,-1.4) {$\ket{\psi}$};
\end{tikzpicture}
```


By Born's rule, we know that $\alpha_0$ and $\alpha_1$ cannot be arbitrary complex numbers: they must satisfy $|\alpha_0|^2+|\alpha_1|^2=1$.
This lets us draw the state vector "geometrically", using the fact that the locus of vectors of magnitude equal to $1$ describes a circle:

```{r,engine='tikz',fig.width=3}
\definecolor{primary}{RGB}{177,98,78}
\definecolor{secondary}{RGB}{91,132,177}
\usetikzlibrary{arrows.meta}
\tikzset{blob/.style args={#1}{circle,draw,fill={#1}}}
\newcommand{\ket}[1]{|#1\rangle}
\begin{tikzpicture}[scale=1.1]
  \draw [->] (-1.3,0) to (1.3,0) node [label=right:{$\ket{0}$}] {};
  \draw [->] (0,-1.3) to (0,1.3) node [label=above:{$\ket{1}$}] {};
  \draw (0,0) circle (1cm);
  \draw [-,ultra thick,primary] (0,0) to (0.51,0);
  \draw [-,ultra thick,primary] (0,0) to (0,0.85);
  \draw [thick,primary,dashed] (0.51,0) to (0.51,0.85);
  \draw [thick,primary,dashed] (0,0.85) to (0.51,0.85);
  \draw [-{Latex},thick,rotate=59,secondary] (0,0) to (1,0);
  \node at (0.7,1.05) {$\ket{\psi}$};
  \node at (0.4,-0.17) {$\alpha_0$};
  \node at (-0.17,0.65) {$\alpha_1$};
\end{tikzpicture}
```

But recall that amplitudes are *complex* numbers, and so $\alpha_0$ and $\alpha_1$ cannot really be drawn as $1$-dimensional *real* vectors on a flat screen or piece of paper;
the picture above provides good intuition, but to be fully accurate we would need to draw it in four-dimensional space (or at least on some three-dimensional paper).

::: {.idea latex=""}
A **qubit** is a quantum system in which the Boolean states $0$ and $1$ are represented by a prescribed pair of normalised and mutually orthogonal quantum states labelled by $\ket{0}$ and $\ket{1}$.
The two states form a so-called **computational** (or **standard**) basis, and so any other state of an isolated qubit can be written as a coherent superposition
$$
  \ket{\psi} = \alpha_0\ket{0} + \alpha_1\ket{1}
$$
for some $\alpha_0$ and $\alpha_1$ such that $|\alpha_0|^2 + |\alpha_1|^2 = 1$.

In practice, a qubit is typically a microscopic system, such as an atom, a nuclear spin, or a polarised photon.
:::

As we have already mentioned, any^[ Here we are talking about *isolated* systems. As you will soon learn, a larger class of physically admissible operations is described by completely positive maps. It may sound awfully complicated but, as you will soon see, it is actually very simple.] computational step, that is, any physically admissible operation $U$ on a qubit, is described by a $(2\times 2)$ unitary matrix $U$.
It modifies the state of the qubit as
$$
  \ket{\psi}
  \longmapsto
  \ket{\psi'}
  = U\ket{\psi}
$$
which we can write explicitly as
$$
  \begin{bmatrix}
    \alpha'_0
  \\\alpha'_1
  \end{bmatrix}
  = \begin{bmatrix}
    U_{00} & U_{01}
  \\U_{10} & U_{11}
  \end{bmatrix}
  \begin{bmatrix}
    \alpha_0
  \\\alpha_1
  \end{bmatrix}
$$
That is, the operation $U$ turns the state $\ket{\psi}$, with components $\alpha_k$, into the state $\ket{\psi'}=U\ket{\psi}$, with components $\alpha'_l= \sum_k U_{lk}\alpha_k$.





## Quantum gates and circuits

<div class="video" title="Multi-qubit circuits" data-videoid="XJy7I3bvr9E"></div>

Atoms, trapped ions, molecules, nuclear spins and many other quantum objects, which we call qubits, can be used to implement simple quantum interference (something which we have still yet to explain), and hence simple quantum computation.
There is no need to learn about physics behind these diverse technologies if all you want is to understand the basics of quantum computation.
We may now conveniently forget about any specific experimental realisation of a qubit and just remember that any manipulations on qubits have to be performed by physically admissible operations, and that such operations are represented by unitary transformations.

::: {.idea latex=""}
A **quantum (logic) gate** is a device which performs a fixed unitary operation on selected qubits in a fixed period of time, and a **quantum circuit** is a device consisting of quantum logic gates whose computational steps are synchronised in time.
The **size** of such a circuit is the number of gates it contains.
:::

Some unitary $U$ acting on a single qubit is represented diagrammatically as

```{r,engine='tikz',engine.opts=list(template="tikz2pdf.tex"),fig.width=1}
\begin{quantikz}
  \qw & \gate{U} & \qw
\end{quantikz}
```

This diagram should be read *from left to right*.
The horizontal line represents a qubit that is inertly carried from one quantum operation to another.
We often call this line a **quantum wire**.
The wire may describe translation in space (e.g. atoms travelling through cavities) or translation in time (e.g. a sequence of operations performed on a trapped ion).
A sequence of two gates acting on the same qubit, say $U$ followed by $V$, is represented by

```{r,engine='tikz',engine.opts=list(template="tikz2pdf.tex"),fig.width=1.5}
\begin{quantikz}
  \qw & \gate{U} & \gate{V} & \qw
\end{quantikz}
```

and is described by the matrix product $VU$ (note the order in which we multiply the matrices).





## Single qubit interference

<div class="video" title="Single qubit interference" data-videoid="eDR-OZZu99M"></div>

Let us now describe what is probably the most important sequence of operations performed on a single qubit: a generic **single-qubit interference**.
It is typically constructed as a sequence of three elementary operations:

1. the **Hadamard gate**
2. a **phase-shift gate**
3. the **Hadamard gate** again.

We represent it graphically as

```{r,engine='tikz',engine.opts=list(template="tikz2pdf.tex"),fig.width=4}
\begin{quantikz}
  \lstick{$\ket{0}$} \qw
  & \gate{H}
  & \phase{\varphi}
  & \gate{H}
  & \qw \rstick{$\cos\frac{\varphi}{2}\ket{0}-i\sin\frac{\varphi}{2}\ket{1}$}
\end{quantikz}
```

where the definitions of the Hadamard and phase-shift gates are as in \@ref(qubits-gates-and-circuits):

::: {.idea latex=""}
|  |  |  |
|:-|:-|:-|
**Hadamard** | $H = \frac{1}{\sqrt{2}}\begin{bmatrix}1&1\\1&-1\end{bmatrix}$ | $\begin{array}{lcr}\ket{0}&\longmapsto&\frac{1}{\sqrt{2}}(\ket{0}+\ket{1})\\\ket{1}&\longmapsto&\frac{1}{\sqrt{2}}(\ket{0}-\ket{1})\end{array}$ | $\begin{array}{lcr}\ket{0}&\longmapsto&\frac{1}{\sqrt{2}}(\ket{0}+\ket{1})\\\ket{1}&\longmapsto&\frac{1}{\sqrt{2}}(\ket{0}+\ket{1})\end{array}$
**Phase-shift** | $P_\varphi = \begin{bmatrix}1&0\\0&e^{i\varphi}\end{bmatrix}$ | $\begin{array}{lcr}\ket{0}&\longmapsto&\ket{0}\\\ket{1}&\longmapsto&e^{i\varphi}\ket{1}\end{array}$ | $\begin{array}{lcr}\ket{0}&\longmapsto&\ket{0}\\\ket{1}&\longmapsto&e^{i\varphi}\ket{1}\end{array}$
:::

Note that we sometimes use the notation $\ket{+}$ and $\ket{-}$ when talking about Hadamard gates, where
$$
  \begin{aligned}
    \ket{+} &\coloneqq H\ket{0} \frac{1}{\sqrt{2}}(\ket{0}+\ket{1})
  \\\ket{-} &\coloneqq H\ket{1} \frac{1}{\sqrt{2}}(\ket{0}-\ket{1}).
  \end{aligned}
$$

You will see this specific sequence of gates over and over again, for it is quantum interference that gives quantum computation additional capabilities.^[Indeed, you have already seen this sequence: recall our study of Ramsey interferometry (Section \@ref(interferometers)), and note how this is essentially the same!]

::: {.idea latex=""}
Something that many explanations of quantum computing say is the following: "quantum computers are quicker because they evaluate all possible solutions at once, in parallel".
**This is not accurate.**

Firstly, quantum computers are not necessarily "quicker" than classical computers, but can simply implement quantum algorithms, *some* of which *are* quicker than their classical counterparts.
Secondly, the idea that they "just do all the possible computations at once" is false --- instead, they rely on thoughtfully using interference (which can be constructive or destructive) to *modify the probabilities of specific outcomes*.

The motto to keep in mind is that *the power of quantum computing comes from quantum interference.*
:::

The product of the three matrices $HP_\varphi H$ describes the action of the whole circuit: it gives the transition amplitudes between states $\ket{0}$ and $\ket{1}$ at the input and the output as
$$
  \frac{1}{\sqrt{2}}
  \begin{bmatrix}
    1 & 1
  \\1 & -1
  \end{bmatrix}
  \begin{bmatrix}
    1 & 0
  \\0 & e^{i\varphi}
  \end{bmatrix}
  \frac{1}{\sqrt{2}}
  \begin{bmatrix}
    1 & 1
  \\1 & -1
  \end{bmatrix}
  = e^{i\frac{\varphi}{2}}
  \begin{bmatrix}
    \cos\varphi/2 & -i\sin\varphi/2
  \\-i\sin\varphi/2 & \cos\varphi/2
  \end{bmatrix}
$$

Given that our input state is almost always $\ket{0}$, it is sometimes much easier and more instructive to step through the execution of this circuit and follow the evolving state.
The interference circuit effects the following sequence of transformations:^[We ignore the global phase factor $e^{i\frac{\varphi}{2}}$.]
$$
  \begin{aligned}
    \ket{0}
    &\xmapsto{H}
    \frac{1}{\sqrt{2}} \left(
      \ket{0}+\ket{1}
    \right)
  \\&\xmapsto{P_\phi}
    \frac{1}{\sqrt{2}} \left(
      \ket{0}+e^{i\phi}\ket{1}
    \right)
  \\&\xmapsto{H}
    \cos\frac{\phi}{2}\ket{0} - i\sin\frac{\phi}{2}\ket{1}.
  \end{aligned}
$$
The first Hadamard gate prepares an equally weighted superposition of $\ket{0}$ and $\ket{1}$ and the second Hadamard closes the interference by bringing the interfering paths together.
The phase shift $\varphi$ in between effectively controls the entire evolution and determines the output.
The probabilities of finding the qubit in state $\ket{0}$ or $\ket{1}$ at the output are, respectively,
$$
  \begin{aligned}
    \Pr(0) &= \cos^2\frac{\phi}{2}
  \\\Pr(1) &= \sin^2\frac{\phi}{2}.
  \end{aligned}
$$
This simple quantum process contains, in a nutshell, the essential ingredients of quantum computation.
This sequence (Hadamard--phase shift--Hadamard) will appear over and over again.
It reflects a natural progression of quantum computation: first we prepare different computational paths, then we evaluate a function which effectively introduces phase shifts into different computational paths, then we bring the computational paths together at the output.





## The square root of NOT

<div class="video" title="The square root of NOT" data-videoid="FyTtG0fM0-0"></div>

Now that we have poked our heads into the quantum world, let us see how quantum interference challenges conventional logic.
Consider the following task:

> Design a logic gate that operates on a single bit and such that when it is followed by another, identical, logic gate the output is always the negation of the input.

Let us call the resulting logic gate **the square root of $\texttt{NOT}$**, or $\sqrt{\texttt{NOT}}$.

```{r,engine='tikz',fig.width=3}
\tikzset{operator/.style={draw,fill=white}}
  \begin{tikzpicture}[scale=1.3]
    \draw [fill=gray!40,rounded corners=2mm] (-1.2,-0.4) rectangle (1.2,0.4);
    \draw (-1.5,0) to (-1,0) to node [operator] {$\sqrt{\texttt{NOT}}$} (0,0) to node [operator] {$\sqrt{\texttt{NOT}}$} (1,0) to (1.5,0);
    \node at (0,-0.65) {$\texttt{NOT}$};
  \end{tikzpicture}
```

A simple check, such as an attempt to construct a truth table, should persuade you that there is no such operation in logic.
It may seem reasonable to argue that since there is no such operation in logic, $\sqrt{\texttt{NOT}}$ is impossible.
But it does exist!
Experimental physicists routinely construct such "impossible" gates in their laboratories.
It is a physically admissible operation described by the unitary matrix^[There are infinitely many unitary operations that act as the square root of $\texttt{NOT}$.]
$$
  \sqrt{\texttt{NOT}}
  = \frac{1}{\sqrt{2}}
  \begin{bmatrix}
    1+i & 1-i
  \\1-i & 1+i
  \end{bmatrix}
  = \frac{1}{\sqrt{2}}
  \begin{bmatrix}
    e^{i\frac{\pi}{4}} & e^{-i\frac{\pi}{4}}
  \\e^{-i\frac{\pi}{4}} & e^{i\frac{\pi}{4}}
  \end{bmatrix}.
$$
Indeed,
$$
  \frac{1}{\sqrt{2}}
  \begin{bmatrix}
    1+i & 1-i
  \\1-i & 1+i
  \end{bmatrix}
  \frac{1}{\sqrt{2}}
  \begin{bmatrix}
    1+i & 1-i
  \\1-i & 1+i
  \end{bmatrix}
  = \begin{bmatrix}
    0&1
  \\1&0
  \end{bmatrix}.
$$

(ref:sqrt-not-caption) A computation that, when repeated, gives exactly $\texttt{NOT}$. An unlabelled line means that it has probability $1$, and the lack of a line corresponds to having probability $0$.

```{r sqrt-not,engine='tikz',fig.cap='(ref:sqrt-not-caption)'}
\tikzset{dot/.style={fill,shape=circle,minimum size=5pt,inner sep=0pt}}
\tikzset{centrelabel/.style={pos=0.5,fill=white}}
\begin{tikzpicture}[xscale=3,yscale=2]
  \node [dot,label=left:{$0$}] (i0) at (0,1) {};
  \node [dot,label=left:{$1$}] (i1) at (0,0) {};
  \node [dot] (m0) at (1,1) {};
  \node [dot] (m1) at (1,0) {};
  \node [dot,label=right:{$0$}] (o0) at (2,1) {};
  \node [dot,label=right:{$1$}] (o1) at (2,0) {};
  \draw [thick] (i0) to node [centrelabel] {$\frac{1+i}{\sqrt{2}}$} (1,1);
  \draw [thick] (i0) to node [pos=0.25,fill=white] {$\frac{1-i}{\sqrt{2}}$} (1,0);
  \draw [thick] (i1) to node [pos=0.25,fill=white] {$\frac{1-i}{\sqrt{2}}$} (1,1);
  \draw [thick] (i1) to node [centrelabel] {$\frac{1+i}{\sqrt{2}}$} (1,0);
  \draw [thick] (m0) to node [centrelabel] {$\frac{1+i}{\sqrt{2}}$} (o0);
  \draw [thick] (m0) to node [pos=0.25,fill=white] {$\frac{1-i}{\sqrt{2}}$} (o1);
  \draw [thick] (m1) to node [pos=0.25,fill=white] {$\frac{1-i}{\sqrt{2}}$} (o0);
  \draw [thick] (m1) to node [centrelabel] {$\frac{1+i}{\sqrt{2}}$} (o1);
  %
  \node at (2.5,0.5) {$=$};
  %
  \node [dot,label=left:{$0$}] (i0) at (3,1) {};
  \node [dot,label=left:{$1$}] (i1) at (3,0) {};
  \node [dot,label=right:{$0$}] (o0) at (4,1) {};
  \node [dot,label=right:{$1$}] (o1) at (4,0) {};
  \draw [thick] (i0) to (o1);
  \draw [thick] (i1) to (o0);
  %
  \node at (0.5,-0.45) {$\sqrt{\texttt{NOT}}$};
  \node at (1.5,-0.45) {$\sqrt{\texttt{NOT}}$};
  \node at (3.5,-0.45) {\texttt{NOT}};
\end{tikzpicture}
```

We could also step through the circuit diagram and follow the evolution of the state vector:

```{r,engine='tikz',fig.width=5}
\tikzset{operator/.style={draw,fill=white}}
\newcommand{\ket}[1]{|#1\rangle}
\begin{tikzpicture}
  \begin{scope}[xscale=3]
    \node (input) at (-1.5,0) {$\ket{0}$};
    \node (inter) at (0,0) {$\frac{1}{\sqrt{2}}\left[e^{i\frac{\pi}{4}}\ket{0}+e^{-i\frac{\pi}{4}}\ket{1}\right]$};
    \node (output) at (1.5,0) {$\ket{1}$};
    \draw[|->] (input) to node[label=above:{$\sqrt{\texttt{NOT}}$}]{} (inter);
    \draw[|->] (inter) to node[label=above:{$\sqrt{\texttt{NOT}}$}]{} (output);
  \end{scope}
\end{tikzpicture}
```

Or, if you prefer to work with column vectors and matrices, you can write the two consecutive application of $\sqrt{\texttt{NOT}}$ to state $\ket{0}$ as^[Just remember that circuits diagrams are read from *left to right*, and vector and matrix operations go from *right to left*.]
$$
  \begin{bmatrix}0\\1\end{bmatrix}
  \,\longleftarrow\!\!\!\vert\,\,
  \frac{1}{\sqrt{2}}
  \begin{bmatrix}
    e^{i\frac{\pi}{4}}
  \\e^{-i\frac{\pi}{4}}
  \end{bmatrix}
  \,\longleftarrow\!\!\!\vert\,\,
  \begin{bmatrix}1\\0\end{bmatrix}
$$
where each "$\longleftarrow\!\!\!\vert$" denotes multiplication by $\frac{1}{\sqrt{2}}\begin{bmatrix}e^{i\frac{\pi}{4}}&e^{-i\frac{\pi}{4}}\\e^{-i\frac{\pi}{4}}&e^{i\frac{\pi}{4}}\end{bmatrix}$.

One way or another, quantum theory explains the behaviour of $\sqrt{\texttt{NOT}}$, and so, reassured by the physical experiments^[One such experiment (which we will soon discuss, in Section \@ref(beamsplitters-against-logic)) is the so-called Mach-Zehnder interferometer.] that corroborate this theory, logicians are now entitled to propose a new logical operation $\sqrt{\texttt{NOT}}$.
Why?
Because a faithful physical model for it exists in nature!





## Phase gates galore {#phase-gates-galore}

We have already met the generic phase gate $P_\varphi=\begin{bmatrix}1&0\\0&e^{i\varphi}\end{bmatrix}$ which acts via
$$
  \begin{array}{lcr}
    \ket{0}&\longmapsto&\ket{0}
  \\\ket{1}&\longmapsto&e^{i\varphi}\ket{1}
  \end{array}
$$
but there are three specific examples of $P_\varphi$ that are important enough to merit their own names (two of which are rather confusing, at first glance).

::: {.idea latex=""}
|  |  |  |
|:-|:-|:-|
**Phase-flip** | $Z = \begin{bmatrix}1&0\\0&-1\end{bmatrix}$ | $\begin{array}{lcr}\ket{0}&\longmapsto&\ket{0}\\\ket{1}&\longmapsto&-\ket{1}\end{array}$
**$\frac{\pi}{4}$-phase** | $S = \begin{bmatrix}1&0\\0&i\end{bmatrix}$ | $\begin{array}{lcr}\ket{0}&\longmapsto&\ket{0}\\\ket{1}&\longmapsto&i\ket{1}\end{array}$
**$\frac{\pi}{8}$-phase** | $T = \begin{bmatrix}1&0\\0&e^{i\frac{\pi}{4}}\end{bmatrix}$ | $\begin{array}{lcr}\ket{0}&\longmapsto&\ket{0}\\\ket{1}&\longmapsto&e^{i\frac{\pi}{4}}\ket{1}\end{array}$
:::

Recall that a phase gate $P_\varphi$ is only defined up to a global phase factor, and so we can write its matrix either as
$$
  P_\varphi =
  \begin{bmatrix}
    1 & 0
  \\0 & e^{i\varphi}
  \end{bmatrix}
$$
or as
$$
  P_\varphi =
  \begin{bmatrix}
    e^{-i\frac{\varphi}{2}} & 0
  \\0 & e^{i\frac{\varphi}{2}}
  \end{bmatrix}
$$
The first version is more common in the quantum information science community, but the second one is sometimes more convenient to use, as it has determinant $1$, and hence belongs to a group called $\mathrm{SU}(2)$.
We will occasionally switch to the $\mathrm{SU}(2)$ version of a phase gates, and this is where the $\frac{\pi}{4}$-phase and $\frac{\pi}{8}$-phase gates get their names, since their $\mathrm{SU}(2)$ versions have $e^{\mp i\pi/4}$ and $e^{\mp i\pi/8}$ (respectively) on the diagonal.

::: {.technical title="SU(2) and SO(3)" latex=""}
We will soon explain what this group $\mathrm{SU}(2)$ is and how it relates to another important group called $\mathrm{SO}(3)$, but it turns up in many places throughout quantum physics, as well as mathematics in general.
Other places you might see $\mathrm{SU}(2)$ appear are when talking about [**quaternions**](https://en.wikipedia.org/wiki/Quaternion) (which are somehow the next thing in the sequence $\mathbb{R}\hookrightarrow\mathbb{C}\hookrightarrow?$) and two of the four "fundamental interactions", namely electromagnetism and the weak nuclear force, which get bundled together into something known as [**electroweak interaction**](https://en.wikipedia.org/wiki/Electroweak_interaction).

We will also eventually talk about how this aforementioned relationship between $\mathrm{SU}(2)$ and $\mathrm{SO}(3)$ lets us describe *rotations* of things in three-dimensional space.
The abstract mathematical concept lying behind this is one with a very lofty-sounding title indeed: **representation theory of Lie algebras**.
This lets us formally talk about things like (non-relativistic) [spin](https://en.wikipedia.org/wiki/Spin_(physics)).
As for this application of $\mathrm{SU}(2)$ in studying the electroweak interaction, this is an example of something known as [**gauge theory**](https://en.wikipedia.org/wiki/Gauge_theory).
:::

The remaining gate, the phase-flip $Z$, is arguably the most important specific phase gate, since it is one of the **Pauli operators**, which we will now discuss.

While we're talking about phase, we should also justify why we keep on saying "let us ignore the global phase factors".
In general, states differing only by a global phase are physically indistinguishable, and so it is *physical experimentation* that leads us to this mathematical choice of only defining things up to a global phase.

::: {.technical title="Global phase" latex=""}
If you are more mathematically minded, then we can justify ignoring the global phase in a few other ways.
Taking the axiomatic approach, where values of physical observables correspond to eigenvalues of operators, think about how the eigenvalues of a matrix $A$ relate to those of the matrix $\mu A$, where $\mu$ is a complex number with $|\mu|=1$.
One "high-level" way of dealing with this, in the language of gauge theory, is to talk of **invariance under gauge symmetry** (here, in particular, we're talking about [$U(1)$](https://en.wikipedia.org/wiki/Circle_group) symmetries).
:::




## Pauli operators {#pauli-operators}

<div class="video" title="Pauli gates, Clifford gates, and the T-gate" data-videoid="WN7sJpsX_G0"></div>

Adding to our collection of common single-qubit gates, we now look at the three **Pauli operators**^[Most of the time we refer to "operators" as "matrices", where the implicit assumption is that we are using the standard basis $\{\ket{0},\ket{1}\}$.] $\sigma_x$, $\sigma_y$, and $\sigma_z$, also denoted by $X$, $Y$, and $Z$, respectively.
These three operators, combined with the identity, satisfy a lot of nice formal properties, which we shall examine briefly here, and then return to in more detail later on, in Section \@ref(pauli-matrices-algebraically).

::: {.idea latex=""}
|  |  |  |
|:-|:-|:-|
**Identity** | $\id = \begin{bmatrix}1&0\\0&1\end{bmatrix}$ | $\begin{array}{lcr}\ket{0}&\longmapsto&\ket{0}\\\ket{1}&\longmapsto&\ket{1}\end{array}$
**Bit-flip** | $X = \begin{bmatrix}0&1\\1&0\end{bmatrix}$ | $\begin{array}{lcr}\ket{0}&\longmapsto&\ket{1}\\\ket{1}&\longmapsto&\ket{0}\end{array}$
**Bit-phase-flip** | $Y = \begin{bmatrix}0&-i\\i&0\end{bmatrix}$ | $\begin{array}{lcr}\ket{0}&\longmapsto&i\ket{1}\\\ket{1}&\longmapsto&-i\ket{0}\end{array}$
**Phase-flip** | $Z = \begin{bmatrix}1&0\\0&-1\end{bmatrix}$ | $\begin{array}{lcr}\ket{0}&\longmapsto&\ket{0}\\\ket{1}&\longmapsto&-\ket{1}\end{array}$
:::

The identity is just a quantum wire, and we have already seen (Section \@ref(phase-gates-galore)) the $X$ and $Z$ gates as the bit-flip and phase-flip, respectively.
Note that, of the $X$ and $Z$ gates, only the $X$ gate has a classical analogue (namely the logical $\texttt{NOT}$ operator).
The remaining gate, the $Y$ operator, describes the combined effect of both the bit- and the phase-flip: $ZX=iY$.

In fact, this is just one of the equations that the Pauli matrices satisfy.
The Pauli matrices are unitary and Hermitian, they square to the identity, and they anti-commute.
By this last point, we mean that
$$
  \begin{aligned}
    XY&=-YX,
  \\XZ&=-ZX,
  \\YZ&=-ZY.
  \end{aligned}
$$
As already mentioned, they satisfy $ZX=iY$, but also any cyclic permutation of this equation (that is, replace $X$ with $Y$, $Y$ with $Z$, and $Z$ with $X$, and repeat this as many times as you wish).

These operators are also called **sigma operators** (usually when we use the notation $\sigma_x$, $\sigma_y$, $\sigma_z$) or (when written as matrices in the standard basis, as we have done) as **Pauli spin matrices**.
They are so ubiquitous in quantum physics that they should certainly be memorised.


### From bit-flips to phase-flips, and back again

The Pauli $Z$ gate is a special case of a phase gate $P_\varphi$ with $\varphi=\pi$.
When we insert it into the interference circuit we obtain

```{r,engine='tikz',engine.opts=list(template="tikz2pdf.tex"),fig.width=4}
\begin{quantikz}
  \qw & \gate{H} & \gate{Z} & \gate{H} & \push{\quad=\quad}
  & \gate{X} & \qw
\end{quantikz}
```

If you wish to verify this, write the Hadamard gate as $H = (X+Z)/\sqrt{2}$ and use the properties of the Pauli operators.
So the Hadamard gate turns phase-flips into bit-flips, but it also turns bit-flips into phase-flips:

```{r,engine='tikz',engine.opts=list(template="tikz2pdf.tex"),fig.width=4}
\begin{quantikz}
  \qw & \gate{H} & \gate{X} & \gate{H} & \push{\quad=\quad}
  & \gate{Z} & \qw
\end{quantikz}
```

Let us also add, for completeness, that $HYH=-Y$.
You will see these identities again and again, especially when we discuss quantum error corrections.^[Unitaries, such as $H$, that take the three Pauli operators to the Pauli operators via conjugation form the so-called **Clifford group**, which we will meet later on. Which phase gate is in the Clifford group of a single qubit?]
$$
  \begin{aligned}
    HXH &= Z
  \\HZH &= X
  \\HYH &= -Y
  \end{aligned}
$$





## Any unitary operation on a single qubit

There are infinitely many **single-qubit unitaries**, i.e. unitary operations that can be performed on a single qubit.
In general, any complex $(n\times n)$ matrix has $n^2$ complex entries, and can thus be specified by $2n^2$ real independent parameters.^[Any complex number $z$ is uniquely specified by two real parameters, writing $z=x+iy$ or $z=re^{i\varphi}$, for example. This is an instance of the fact that $\mathbb{C}$ is a two-dimensional vector space over $\mathbb{R}$.]
The unitarity constraint removes $n^2$ of these (why? the argument is that once we specify $n^2$ parameters, the rest are uniquely determined by solving the equation that needs to be satisfied in order for the matrix to be unitary).
So any unitary $(n\times n)$ matrix has $n^2$ real independent parameters.

::: {.technical title="Parameter counting" latex=""}
This sort of argument --- counting how many parameters determine a family of matrices --- is really an example of calculating the dimension of a vector space.
More generally, saying things like "imposing a polynomial equation condition on the coefficients lowers the number of (complex) parameters necessary by $1$" is the bread and butter of [algebraic geometry](https://en.wikipedia.org/wiki/Algebraic_geometry), where we try to understand how satisfying polynomial equations can be interpreted as geometrically modifying high-dimensional "shapes".
:::

In particular, we need _four_ real parameters to specify a $(2\times 2)$ unitary matrix.
If we are prepared to ignore global phase factors (which we are!) then there are only three real parameters left.
The real question is, can we use this to construct and implement *any* unitary on a single qubit in some simple way?

Delightfully, the answer is _yes, we can._

Any unitary operation on a qubit (up to an overall multiplicative phase factor) can be implemented by a circuit containing just two Hadamards and three phase gates, with adjustable phase settings, as in Figure \@ref(fig:universal-circuit-for-2-by-2).

(ref:universal-circuit-for-2-by-2-caption) The universal circuit for unitary $(2\times2)$ matrices, exhibiting how any such matrix is uniquely determined (up to a global phase) by three real parameters.

```{r universal-circuit-for-2-by-2,engine='tikz',engine.opts=list(template="tikz2pdf.tex"),fig.width=4,fig.cap='(ref:universal-circuit-for-2-by-2-caption)'}
\begin{quantikz}
  \qw & \phase{\alpha} & \gate{H} & \phase{\varphi} & \gate{H} & \phase{\beta} & \qw
\end{quantikz}
```

If we multiply the matrices^[Remember that the order of matrix multiplication is reversed when compared to reading circuit diagrams.] corresponding to each gate in the network we obtain the single matrix
$$
  U(\alpha,\beta,\varphi)
  =\begin{bmatrix}
    e^{-i\left(\frac{\alpha+\beta}{2}\right)}\cos\varphi/2
    & -ie^{i\left(\frac{\alpha-\beta}{2}\right)}\sin\varphi/2
  \\-ie^{-i\left(\frac{\alpha-\beta}{2}\right)}\sin\varphi/2
    & e^{i\left(\frac{\alpha+\beta}{2}\right)}\cos\varphi/2
  \end{bmatrix}.
$$
Any $(2\times 2)$ unitary matrix (up to global phase) can be expressed in this form using the three independent real parameters, $\alpha$, $\beta,$ and $\varphi$, which take values in $[0,2\pi]$.
In order to see that this construction does what it claims, let us explore an intriguing mathematical connection between single-qubit unitaries and rotations in three dimensions.





## The Bloch sphere {#the-bloch-sphere}

<div class="video" title="The Bloch sphere" data-videoid="_UYZYXTaRYM"></div>

<div class="video" title="Pauli and Clifford gates on the Bloch sphere" data-videoid="YMw-Kbfqtf4"></div>

Unitary operations on a single qubit form a group.
More precisely, the set of all $(2\times 2)$ unitary matrices forms a (*non-abelian*) group under matrix multiplication, denoted by $\mathrm{U}(2)$.
It turns out that compositions of single-qubit unitaries behave pretty much the same as compositions of rotations in three dimensions.
Technically speaking, we claim that $\mathrm{U}(2)/\mathrm{U}(1)\cong \mathrm{SO}(3)$.^[Note that $\mathrm{U}(1)\cong\mathbb{C}^\times$, where $\mathbb{C}^\times$ is the multiplicative group of invertible elements of the complex numbers, i.e. the set $\mathbb{C}\setminus\{0\}$ with the group operation given by multiplication.]
That is, $(2\times 2)$ unitaries, up to global phase, form a group which is isomorphic to the group of rotations in three dimensions, which denoted by $\mathrm{SO}(3)$.
This isomorphism helps to visualise the actions of single-qubit gates.

There are many ways to introduce this isomorphism.
Here we will just show how to represent single-qubit state vectors in terms of Euclidean vectors in three dimensions; later (in Section \@ref(unitaries-as-rotations)) we will actually relate unitary operations on state vectors to rotations in this Euclidean space, demonstrating this isomorphism.^[That is, we have the group $\mathrm{U}(2)$ acting on the space of single-qubit state vectors, and we have the group $\mathrm{SO}(3)$ acting on the unit sphere $S^2\subset\mathbb{R}^3$. In this chapter we will discuss how to go from one *space* (i.e. the thing being acted upon) to the other; in Section \@ref(unitaries-as-rotations we will discuss how to go from one *group* (i.e. the thing doing the acting) to the other.]

Any single-qubit state can be written as $\ket{\psi}=\alpha\ket{0}+\beta\ket{1}$, constrained by the relation $|\alpha|^2+|\beta|^2=1$.
This suggests a more natural parametrisation as
$$
  \ket{\psi} =
  \cos(\theta/2)e^{i\varphi_0}\ket{0} + \sin(\theta/2)e^{i\varphi_1}\ket{1}
$$
(note that there is a good reason to use $\theta/2$ instead of $\theta$, and we we will explain why later on).
We can then factor out a global phase:
$$
  \ket{\psi} =
  e^{i\varphi_0}\left(
    \cos(\theta/2)\ket{0} + \sin(\theta/2)e^{i\varphi}\ket{1}
  \right),
$$
and even remove it completely, since states that are identical up to a global phase are physically indistinguishable.

The parametrisation in terms of $\theta$ and $\varphi$ should remind you (if you are familiar with it) of [spherical polar coordinates](https://en.wikipedia.org/wiki/Spherical_coordinate_system) for the surface of a sphere.

(ref:bloch-sphere-caption) The Bloch sphere, with the point $\vec{s}$ corresponding to $\ket{\psi}$ marked.

```{r bloch-sphere,engine='tikz',fig.width=4,fig.cap='(ref:bloch-sphere-caption)'}
\usetikzlibrary{arrows.meta}
\tikzset{dot/.style={fill,shape=circle,minimum size=5pt,inner sep=0pt}}
\definecolor{primary}{RGB}{177,98,78}
\definecolor{secondary}{RGB}{91,132,177}
\newcommand{\ket}[1]{|#1\rangle}
\begin{tikzpicture}
  \shade [ball color=gray!40,opacity=0.4] (0,0) circle (2cm);
  \draw (0,0) circle (2cm);
  \draw (-2,0) arc (180:360:2 and 0.9);
  \draw [dashed,thin] (2,0) arc (0:180:2 and 0.9);
  %
  \node [label=above:{$\ket{0}$}] (top) at (0,2) {};
  \node [label=right:{$y$}] (right) at (2,0) {};
  \node [label=below:{$\ket{1}$}] (bottom) at (0,-2) {};
  \node (front) at (225:1.2) {};
  \node at (225:1.4) {$x$};
  \draw [<->] (bottom) to (top);
  \draw [->] (0,0) to (right);
  \draw [->] (0,0) to (front);
  %
  \draw [thin,fill=primary!80] (0,0) to (0,0.72) to [bend left] (0.35,0.525) to cycle;
  \draw [thin,fill=primary!80] (0,0) to (0.48,-0.3) to [bend left] (225:0.5) to cycle;
  \node at (0.15,0.45) {$\theta$};
  \node [fill=primary!80,inner sep=0] at (0.05,-0.25) {$\varphi$};
  %
  \node [fill,shape=circle,minimum size=3pt,inner sep=0pt] (origin) at (0,0) {};
  \node [dot,secondary,label=right:{$\vec{s}$}] (vector) at (0.8,1.2) {};
  \draw [-Latex,secondary] (origin) to (vector);
  \draw [dashed,ultra thick] (vector) to (0.8,-0.5) to (origin);
\end{tikzpicture}
```

We call this sphere the **Bloch sphere**, and the unit vector $\vec{s}$ defined by $\theta$ and $\varphi$ the **Bloch vector**.
This is a very useful way to visualise quantum states of a single qubit and unitary operations that we perform on it.
Any unitary action on the state vector will induce a rotation of the corresponding Bloch vector.
But what kind of rotation?

We give a complete answer to this question soon, in Section \@ref(unitaries-as-rotations), but we might as well give some specific results here first, since some are easy enough to calculate "by hand".
Here is one fundamental observation: *any two orthogonal state vectors appear on the Bloch sphere as two Bloch vectors pointing in opposite directions*.
Now, the two eigenvectors of a single-qubit unitary $U$ are always orthogonal, and so must define an axis running through the centre of the Bloch sphere.
*This* is the axis about which the Bloch vector is rotated when $U$ acts on the corresponding state vector.
The rotation angle $\alpha$ is given by the eigenvalues of $U$, which, up to a global phase factor, are of the form $e^{\mp i\alpha/2}$.

It is instructive to work out few simple cases and get a feel for the rotations corresponding to the most common unitaries.
For example, it is easy to check that a phase gate $P_\alpha$ acts by
$$
  \cos\frac{\theta}{2}\ket{0} + e^{i\varphi}\sin\frac{\theta}{2}\ket{1}
  \longmapsto
  \cos\frac{\theta}{2}\ket{0} + e^{i(\varphi+\alpha)}\sin\frac{\theta}{2}\ket{1}.
$$
The azimuthal angle changes from $\varphi$ to $\varphi+\alpha$, and so the Bloch sphere is rotated anticlockwise by $\alpha$ about the $z$-axis.
The Bloch vectors corresponding to the two eigenvectors of $P_\alpha$, namely $\ket{0}$ and $\ket{1}$, define the axis of the rotation.

(ref:bloch-sphere-rotation-caption) Phase gates $P_\alpha$ represent rotations of the Bloch sphere around the $z$-axis.

```{r bloch-sphere-rotation,engine='tikz',fig.width=5,fig.cap='(ref:bloch-sphere-rotation-caption)'}
\usetikzlibrary{arrows.meta}
\definecolor{primary}{RGB}{177,98,78}
\definecolor{secondary}{RGB}{91,132,177}
\begin{tikzpicture}
  \shade [ball color=gray!40,opacity=0.4] (0,0) circle (2cm);
  \draw (0,0) circle (2cm);
  \draw (-2,0) arc (180:360:2 and 0.9);
  \draw [dashed,thin] (2,0) arc (0:180:2 and 0.9);
  %
  \draw [<->,secondary] (0,-3) to (0,3);
  \draw [->,thin] (0,0) to (1,0);
  \draw [->,thin] (0,0) to (225:0.7);
  %
  \node [fill,shape=circle,minimum size=3pt,inner sep=0pt,label=above:{$\vec s$}] at (-1.15,0.85) {};
  \draw [-Latex,primary] (-1,0.7) arc (200:320:1 and 0.4);
  \node [fill,shape=circle,minimum size=3pt,inner sep=0pt,label=above:{$P_\alpha\vec s$}] at (0.85,0.65) {};
  %
  \draw [-Latex,ultra thick,primary] (-2.5,0.2) arc (160:400:2.75 and 1.2);
\end{tikzpicture}
```

As previously mentioned, the Pauli operator  $Z=\sigma_z$ is a special case of a phase gate, and represents rotation by ${180}^{\circ}$ (that is, $\pi$ radians), about the $z$-axis.
You can also verify that $X=\sigma_x$, with eigenvectors ${(\ket{0}\pm\ket{1})/\sqrt{2}}$, represents rotation by ${180}^{\circ}$ about the $x$-axis, and $Y=\sigma_y$, with eigenvectors ${(\ket{0}\pm i\ket{1})/\sqrt{2}}$, represents rotation by ${180}^{\circ}$ about the $y$-axis.
Again, note that, by the definition of the axis, the points of intersection of these axes with the Bloch sphere are exactly the eigenvectors of the operator.

How about the Hadamard gate?
Like the Pauli operators, it squares to the identity ($H^2=\id$), which implies that its eigenvalues are $\pm 1$.
Thus it will correspond to a rotation by ${180}^{\circ}$.
But about which axis?
This time, rather than finding eigenvectors of $H$, we notice that $HXH=Z$ and $HZH=X$, thus $H$ must swap the $x$- and $z$-axes, turning rotations about the $z$-axis into rotations about the $x$-axis, and vice versa.
The Hadamard gate must then represent rotation by ${180}^{\circ}$ about the diagonal $(x+z)$-axis.
You may also notice that, after this rotation, the $y$-axis points in the opposite direction, which seems to be related to another identity: $HYH=-Y$.
This is not a coincidence!

We will eventually show that the effect of the rotation represented by unitary $U$ on the Bloch vector with components $s_x$, $s_y$, $s_z$ is summarised in the formula
$$
  U (s_x X + s_y Y + s_z Z) U^\dagger
  = s'_x X+ s'_y Y + s'_z Z,
$$
where $s'_x$, $s'_y$, and $s'_z$ are the components of the rotated Bloch vector.



### Drawing points on the Bloch sphere

We know that the state $\ket{0}$ corresponds to the north pole of the Bloch sphere, and the state $\ket{1}$ to the south, but what about an arbitrary state $\ket{\psi}=\alpha\ket{0}+\beta\ket{1}$?
By definition, we can find the parametrisation in terms of $\theta$ and $\varphi$, but there is also a neat "trick" for finding the point on the Bloch sphere that corresponds to $\ket{\psi}$, which goes as follows.

1. Calculate $\lambda=\beta/\alpha$ (assuming that $\alpha\neq0$, since otherwise $\ket{\psi}=\ket{1}$).
2. Write $\lambda=\lambda_x+i\lambda_y$ and mark the point $p=(\lambda_x,\lambda_y)$ in the $xy$-plane (i.e. the plane $\{z=0\}$).
3. Draw the line going through the south-pole (which corresponds to $\ket{1}$) and the point $p$. This will intersect the Bloch sphere in exactly one other point, and this is exactly the point corresponding to $\ket{\psi}$.

Note that this lets you _draw_ the point on the sphere, but doesn't (immediately) give you the _coordinates_ for it.
That is, this method is nice for geometric visualisation, but the parametrisation method is much better when it comes to actually doing calculations.





## Composition of rotations {#composition-of-rotations}

<div class="video" title="Unitaries as three rotations" data-videoid="OdNn9vT77OY"></div>

We are now in a position understand the circuit in Figure \@ref(fig:universal-circuit-for-2-by-2) in geometric terms.
It is a [very useful fact of geometry](https://en.wikipedia.org/wiki/Euler_angles#Conventions_by_extrinsic_rotations) (which we shall take for granted) that *any* rotation in three-dimensional Euclidean space can be performed as a sequence of three specific rotations: one about the $z$-axis, one about the $x$-axis, and one more about $z$-axis.
The circuit does exactly this:

```{r,engine='tikz',engine.opts=list(template="tikz2pdf.tex"),fig.width=3.5}
\begin{quantikz}
  \qw & \phase{\alpha} & \gate{H}\gategroup[1,steps=3,background,style={fill=gray!20,rounded corners}]{} & \phase{\varphi} & \gate{H} & \phase{\beta} & \qw
\end{quantikz}
```

The first phase gate effects rotation by $\alpha$ about the $z$-axis, the second phase gate is sandwiched between the two Hadamard gates, and these three gates together effect rotation by $\varphi$ about the $x$-axis, and, finally, the third phase gates effects rotation by $\beta$ about the $z$-axis.
So we can implement any unitary $U$ by choosing the three phase shifts, $\alpha$, $\varphi$, and $\beta$, which are known as the three [**Euler angles**](https://en.wikipedia.org/wiki/Euler_angles).






## A finite set of universal gates {#finite-set-of-universal-gates}

<div class="video" title="Approximating unitaries" data-videoid="0bQ2P7npuUA"></div>

The Hadamard gate and the phase gates, with adjustable phases, allow us to implement an arbitrary single-qubit unitary _exactly_.
The tacit assumption here is that we have here _infinitely many_ phase gates: one gate for each phase.
In fact, we can pick just one phase gate, namely any phase gate $P_\alpha$ with the phase $\alpha$ that is incommensurate^[That is, there do _not_ exist any $m,n\in\mathbb{Z}$ such that $m\alpha=n\pi$. For example, it suffices to take $\alpha$ to be rational, since $\pi$ is irrational.] with $\pi$.
It is clear that repeated iteration of $P_\alpha$ can be used to approximate any other phase gate to arbitrary accuracy: indeed, rotate the Bloch sphere by $\alpha$ about the $z$-axis sufficiently many times and you end up as close as you please to any other rotation about the $z$-axis.

If you want to be $\varepsilon$-close to the desired angle of rotation, then you may need to repeat the rotation by $\alpha$ roughly $1/\varepsilon$ times.
Indeed, within $n$ applications (for^[The notation $x\gg y$ is rather imprecise, but it basically means "$x$ is much much larger than $y$, and, in particular, large enough for whatever we are claiming to be true".] $n\alpha\gg 2\pi$) of $P_\alpha$, we expect the accessible angles to be approximately evenly distributed within the range $[0,2\pi]$, i.e. any angle of rotation can be achieved to an accuracy of $\varepsilon=2\pi/n$ by using up to $n\approx 1/\varepsilon$ applications of $P_\alpha$.
So we can use *just one* phase gate to *approximate* the *three* phase gates in the circuit in Figure \@ref(fig:universal-circuit-for-2-by-2).

There are other ways of implementing irrational rotations of the Bloch sphere.
For example, take the Hadamard gate and the $T$ gate (also known as the $\frac{\pi}{8}$-phase gate, as we saw earlier in \@ref(phase-gates-galore)).
You can check that the compositions $THTH$ and $HTHT$ represent rotations by angles which are irrational multiples of $\pi$, about two different axes.
We can then compose a sequence of these two rotations to approximate any other rotation of the sphere.
This may look very nice in theory, but there are issues with the actual physical implementation of this approach: in reality, all the gates in the circuit will operate with only *finite* precision, and the phase gates will deviate from implementing the required *irrational* rotations.
It turns out, however, that we can tolerate minor imperfections; the final result will not be that far off.





## *Remarks and exercises* {#remarks-and-exercises-2}

### Unknown phase

Consider the usual quantum interference circuit:

```{r,engine='tikz',engine.opts=list(template="tikz2pdf.tex"),fig.width=2.5}
\begin{quantikz}
  \lstick{$\ket{0}$} \qw
  & \gate{H}
  & \phase{\varphi}
  & \gate{H}
  & \qw \rstick{$\ket{1}$}
\end{quantikz}
```

Suppose you can control the input of the circuit and measure the output, but you do not know the phase shift $\varphi$ introduced by the phase gate.
You prepare input $\ket{0}$ and register output $\ket{1}$.
What can you say about $\varphi$?

Now you are promised that $\varphi$ is either $0$ or $\pi$.
You can run the circuit *only once* to find out which of the two phases was chosen.
Is it possible to then always correctly guess whether $\varphi$ was $0$ or $\pi$?


### One of the many cross-product identities {#cross-product-identity}

When working with three-dimensional geometry, the [cross product](https://en.wikipedia.org/wiki/Cross_product) of vectors is very useful, so here is an exercise to help you get used to working with it.
Derive the identity
$$
  (\vec{a}\cdot\vec{\sigma})(\vec{b}\cdot\vec{\sigma})
  = (\vec{a}\cdot\vec{b})\id + i(\vec{a}\times \vec{b})\cdot \vec{\sigma}.
$$

*Hint: all you need here are the Pauli matrices' commutation and anti-commutation relations, but it is instructive to derive the identity using the component notation, and below we give a sketch of how such a derivation would go.*

First, notice that the products of Pauli matrices can be written succinctly as
$$
 \sigma_{i}\sigma_{j}
 = \delta _{ij}\id + i\varepsilon_{ijk}\,\sigma _{k},
$$
where $\delta_{ij}$ is [**Kronecker delta**](https://en.wikipedia.org/wiki/Kronecker_delta) (equal to $0$ if $i\neq j$, and to $1$ if $i=j$) and $\varepsilon_{ijk}$ is the [**Levi-Civita symbol**](https://en.wikipedia.org/wiki/Levi-Civita_symbol#Three_dimensions):
$$
 \varepsilon_{ijk}
 = \begin{cases}
  +1 & {\text{if }}(i,j,k){\text{ is }}(1,2,3)\text{, }(2,3,1){\text{, or }}(3,1,2)
\\-1 & {\text{if }}(i,j,k){\text{ is }}(3,2,1)\text{, }(1,3,2){\text{, or }}(2,1,3)
\\\;\;\;0 & {\text{if }}i=j,{\text{ or }}j=k,{\text{ or }}k=i
\end{cases}
$$
That is, $\varepsilon _{ijk}$ is $1$ if $(i, j, k)$ is an even permutation of $(1, 2, 3)$, it is $-1$ if it is an odd permutation, and it is $0$ if any index is repeated.
The Levi-Civita symbol is anti-symmetric, meaning when any two indices are changed, its sign alternates.
Then recall that the scalar (dot) product and vector (cross) product of two Euclidean vectors $\vec{a}$ and $\vec{b}$ can be written, in terms of the components, as
$$
  \begin{aligned}
    \vec{a}\cdot\vec{b}
    &= \sum_{i=1}^3 a_i b_i
  \\(\vec{a}\times\vec{b})_i
    &= \sum_{j,k=1}^3 \varepsilon_{ijk}a_jb_k.
  \end{aligned}
$$
The rest is rather straightforward:
$$
  (\vec{a}\cdot\vec{\sigma})(\vec{b}\cdot\vec{\sigma})
  = \sum_{i,j}a_i b_j\sigma_i\sigma_j
  = \ldots.
$$
